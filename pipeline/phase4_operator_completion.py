import csv
import os
from collections import defaultdict
from evodex.operators import extract_operator
from evodex.utils import reaction_hash
from pipeline.config import load_paths
from pipeline.version import __version__
import time
import sys
csv.field_size_limit(sys.maxsize)
import pandas as pd
from evodex.astatine import  convert_dataframe_smirks_column_at_to_h


# Phase 4: Operator Completion
# This script derives additional operator forms (EVODEX-C, EVODEX-N, EVODEX-Em, EVODEX-Cm, EVODEX-Nm)
# from the pruned EVODEX-P reactions. Each operator is generated by applying distinct operator extraction 
# settings to the EVODEX-P SMIRKS. The resulting operators are deduplicated by hash and written to output.

def main():
    start_time = time.time()
    print("Phase 4 operator completion started...")
    paths = load_paths('pipeline/config/paths.yaml')

    operator_configs = {
        'evodex_c': dict(include_stereochemistry=True, include_sigma=False, include_pi=False,
                         include_unmapped_hydrogens=True, include_unmapped_heavy_atoms=True, include_static_hydrogens=True),
        'evodex_n': dict(include_stereochemistry=True, include_sigma=True, include_pi=False,
                         include_unmapped_hydrogens=True, include_unmapped_heavy_atoms=True, include_static_hydrogens=True),
        'evodex_em': dict(include_stereochemistry=False, include_sigma=True, include_pi=True,
                          include_unmapped_hydrogens=False, include_unmapped_heavy_atoms=False, include_static_hydrogens=False),
        'evodex_cm': dict(include_stereochemistry=False, include_sigma=False, include_pi=False,
                          include_unmapped_hydrogens=False, include_unmapped_heavy_atoms=False, include_static_hydrogens=False),
        'evodex_nm': dict(include_stereochemistry=False, include_sigma=True, include_pi=False,
                          include_unmapped_hydrogens=False, include_unmapped_heavy_atoms=False, include_static_hydrogens=False),
    }

    operator_maps = {key: defaultdict(lambda: {'smirks': None, 'sources': set()}) for key in operator_configs}

    with open(paths['evodex_p_phase3c_final'], 'r') as infile:
        reader = csv.DictReader(infile)
        for row in reader:
            evodex_p_id = row['id']
            smirks = row['smirks']

            for key, params in operator_configs.items():
                try:
                    op_smirks = extract_operator(smirks, **params)
                    if op_smirks.startswith(">>") or op_smirks.endswith(">>"):
                        raise ValueError(f"Invalid operator extracted for P {evodex_p_id}: {op_smirks}")
                    op_hash = reaction_hash(op_smirks)
                    # print(f"{key}: P {evodex_p_id} → operator hash {op_hash} → smirks {op_smirks}")
                    operator_maps[key][op_hash]['smirks'] = op_smirks
                    operator_maps[key][op_hash]['sources'].add(evodex_p_id)
                except Exception:
                    continue

    for key, data_map in operator_maps.items():
        out_path = paths[key]
        # Sort operators by source count (descending)
        sorted_ops = sorted(data_map.items(), key=lambda item: len(item[1]['sources']), reverse=True)
        with open(out_path, 'w', newline='') as outfile:
            writer = csv.DictWriter(outfile, fieldnames=['id', 'smirks', 'sources'])
            writer.writeheader()
            for idx, (rxn_hash, data) in enumerate(sorted_ops, start=1):
                op_code = key.split('_')[1]
                op_id = f"EVODEX.1-{op_code[0].upper()}{op_code[1:]}{idx}"
                writer.writerow({'id': op_id, 'smirks': data['smirks'], 'sources': ','.join(sorted(data['sources']))})

    # Validation: Check for operator fragmentation per EVODEX-E
    print("Validating EVODEX-E → Operator mappings for consistency...")

    # Load EVODEX-E to map E → P sources
    evodex_e_to_p = {}
    with open(paths['evodex_e_phase3c_final'], 'r') as infile:
        reader = csv.DictReader(infile)
        for row in reader:
            evodex_e_id = row['id']
            p_sources = row['sources'].split(',')
            evodex_e_to_p[evodex_e_id] = set(p_sources)

    # For each ERO, check if its P sources produce consistent operator hashes
    fragmentation_log = []

    for evodex_e_id, p_sources in evodex_e_to_p.items():
        for key, data_map in operator_maps.items():
            # Build reverse map: P → hash
            p_to_hash = {}
            for rxn_hash, data in data_map.items():
                for p_id in data['sources']:
                    p_to_hash[p_id] = rxn_hash

            # Find operator hashes for this E's P sources
            hashes = set(p_to_hash.get(p_id) for p_id in p_sources if p_id in p_to_hash)

            if len(hashes) > 1:
                fragmentation_log.append({
                    'evodex_e': evodex_e_id,
                    'operator': key.upper(),
                    'num_hashes': len(hashes),
                    'hashes': list(hashes),
                })

    # Print detailed summary
    if fragmentation_log:
        print("\n=== Fragmentation Detected ===\n")

        # Load EVODEX-E smirks
        evodex_e_smirks = {}
        with open(paths['evodex_e_phase3c_final'], 'r') as infile:
            reader = csv.DictReader(infile)
            for row in reader:
                evodex_e_smirks[row['id']] = row['smirks']

        # For each operator type, also build reverse map: hash → (smirks, sources)
        operator_hash_details = {}
        for key, data_map in operator_maps.items():
            operator_hash_details[key] = {}
            for rxn_hash, data in data_map.items():
                operator_hash_details[key][rxn_hash] = {
                    'smirks': data['smirks'],
                    'sources': sorted(data['sources'])
                }

        for frag in fragmentation_log:
            evodex_e_id = frag['evodex_e']
            operator = frag['operator']
            hashes = frag['hashes']
            print(f"EVODEX-E {evodex_e_id} (SMIRKS: {evodex_e_smirks.get(evodex_e_id, 'N/A')})\n")
            print(f"→ {operator}: {len(hashes)} variants")
            for idx, h in enumerate(sorted(hashes), 1):
                op_detail = operator_hash_details[operator.lower()][h]
                sources_str = ', '.join(op_detail['sources'])
                print(f"  Variant {idx}:")
                print(f"    Sources: {sources_str}")
                print(f"    SMIRKS: {op_detail['smirks']}\n")

        total_fragmented_eros = len({frag['evodex_e'] for frag in fragmentation_log})
        print(f"Total fragmented EROs: {total_fragmented_eros}\n")
    else:
        print("No fragmentation detected — all EVODEX-E map consistently to operators.")

    # Write fragmentation report to file
    frag_report_path = os.path.join(paths['errors_dir'], 'Phase4_fragmentation_report.txt')
    with open(frag_report_path, 'w') as frag_file:
        frag_file.write("EVODEX-E\tOperator\tNumHashes\tHashes\n")
        for frag in fragmentation_log:
            frag_file.write(f"{frag['evodex_e']}\t{frag['operator']}\t{frag['num_hashes']}\t{','.join(str(h) for h in frag['hashes'])}\n")

    import statistics

    # Generate Phase 4 mining report
    print("Generating Phase 4 mining report...")

    report_lines = [
        f"EVODEX Phase 4 Operator Completion Report (version {__version__})",
        "=============================================================",
    ]

    for key, data_map in operator_maps.items():
        op_code = key.split('_')[1]
        op_prefix = f"EVODEX_{op_code[0].upper()}{op_code[1:]}"
        counts = [len(data['sources']) for data in data_map.values()]
        report_lines.extend([
            f"{op_prefix}:",
            f"Total unique {op_prefix} entries: {len(counts)}",
            f"Min sources per {op_prefix}: {min(counts) if counts else 0}",
            f"Max sources per {op_prefix}: {max(counts) if counts else 0}",
            f"Mean sources per {op_prefix}: {statistics.mean(counts) if counts else 0:.2f}",
            f"Median sources per {op_prefix}: {statistics.median(counts) if counts else 0}",
            ""
        ])

    # Print to console
    for line in report_lines:
        print(line)

    # Write report to file
    report_path = os.path.join(paths['errors_dir'], 'Phase4_evodex_report.txt')
    with open(report_path, 'w') as report_file:
        report_file.write('\n'.join(report_lines))

    # === Phase 4 Publishing ===
    print("\n=== Phase 4 Publishing ===")
    
    for key in operator_configs:
        # Determine canonical filename (matches what was written in processed)
        out_filename = os.path.basename(paths[key])
        src_path = paths[key]
        dst_path = os.path.join('evodex', 'data', out_filename)

        print(f"Publishing {out_filename} to evodex/data...")

        # Load processed file
        df = pd.read_csv(src_path)

        # Convert At → H on smirks column
        df_h, errors = convert_dataframe_smirks_column_at_to_h(df, 'smirks')
        if errors:
            print(f"  [!] {len(errors)} At→H conversion errors encountered.")

        # Write to evodex/data
        df_h.to_csv(dst_path, index=False)

    end_time = time.time()
    elapsed_time = end_time - start_time
    print(f"Phase 4 operator completion completed in {elapsed_time:.2f} seconds.")

if __name__ == "__main__":
    main()
